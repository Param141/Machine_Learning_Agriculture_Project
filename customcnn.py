# -*- coding: utf-8 -*-
"""CustomCNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15AGfFOq1UvfSxy3G7v4GEn7RjY98dy_Y
"""

from google.colab import drive
drive.mount('/content/drive')

!ls "/content/drive/MyDrive"

import zipfile
import os

# Correct path to your dataset zip file
zip_path = "/content/drive/MyDrive/leaf_data_training.zip"
extract_path = "/content/dataset"

# Extract only if not already extracted
if not os.path.exists(extract_path):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_path)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

import numpy as np

dataset_path = "/content/dataset"

datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

train_ds = datagen.flow_from_directory(
    dataset_path,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='training'
)

val_ds = datagen.flow_from_directory(
    dataset_path,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)

# Show class names and sample counts from train_ds
print("Class indices:", train_ds.class_indices)
print("Number of training images:", train_ds.samples)
print("Number of validation images:", val_ds.samples)

# Show a few training images
import matplotlib.pyplot as plt

x, y = next(train_ds)  # âœ… Corrected line here
plt.figure(figsize=(10, 10))
for i in range(9):
    plt.subplot(3, 3, i + 1)
    plt.imshow(x[i])
    plt.title(f"Label: {int(y[i])}")  # Casting float label to int
    plt.axis("off")
plt.tight_layout()
plt.show()

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import seaborn as sns

def evaluate_model(model, val_ds):
    val_preds = model.predict(val_ds)
    y_pred = np.argmax(val_preds, axis=1)
    y_true = val_ds.classes

    acc = accuracy_score(y_true, y_pred) * 100
    prec = precision_score(y_true, y_pred, average='macro') * 100
    rec = recall_score(y_true, y_pred, average='macro') * 100
    f1 = f1_score(y_true, y_pred, average='macro') * 100

    print(f"Accuracy: {acc:.2f}%")
    print(f"Precision: {prec:.2f}%")
    print(f"Recall: {rec:.2f}%")
    print(f"F1 Score: {f1:.2f}%")

    # Confusion matrix
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
    plt.title("Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

    return acc, prec, rec, f1

import tensorflow as tf
from tensorflow.keras import layers, models

# === Model 1: Custom CNN ===
model1 = tf.keras.Sequential([
    layers.Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),
    layers.MaxPooling2D(2,2),

    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D(2,2),

    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])

model1.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

history1 = model1.fit(
    train_ds,
    validation_data=val_ds,
    epochs=5
)

# Evaluate the model
print("\nEvaluation results for Custom CNN:")
evaluate_model(model1, val_ds)

import numpy as np
unique_classes = np.unique(val_ds.classes)
print("Validation classes present:", unique_classes)

import os

dataset_path = "/content/dataset"

# List all folders/files in dataset root
print("Root folders/files in dataset:")
print(os.listdir(dataset_path))

# If you see any folder like 'Disease' inside, list its content too
disease_folder = os.path.join(dataset_path, "Disease")
if os.path.exists(disease_folder):
    print("\n'Disease' folder contents:")
    print(os.listdir(disease_folder))
else:
    print("\nNo 'Disease' folder found inside dataset.")

import os

leaf_data_path = "/content/dataset/leaf_data_training"
print("Folders/files inside leaf_data_training:")
print(os.listdir(leaf_data_path))

from tensorflow.keras.preprocessing.image import ImageDataGenerator

leaf_data_path = "/content/dataset/leaf_data_training"

datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

train_ds = datagen.flow_from_directory(
    leaf_data_path,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='training',
    shuffle=True,
    seed=42
)

val_ds = datagen.flow_from_directory(
    leaf_data_path,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='validation',
    shuffle=False,
    seed=42
)

print("Training classes:", train_ds.class_indices)
print("Number of training samples:", train_ds.samples)
print("Validation classes:", val_ds.class_indices)
print("Number of validation samples:", val_ds.samples)

import numpy as np
print("Unique training labels:", np.unique(train_ds.classes))
print("Unique validation labels:", np.unique(val_ds.classes))

import tensorflow as tf
from tensorflow.keras import layers, models
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns

def create_custom_cnn():
    model = models.Sequential([
        layers.Input(shape=(224, 224, 3)),
        layers.Conv2D(32, (3,3), activation='relu'),
        layers.MaxPooling2D(2,2),

        layers.Conv2D(64, (3,3), activation='relu'),
        layers.MaxPooling2D(2,2),

        layers.Conv2D(128, (3,3), activation='relu'),
        layers.MaxPooling2D(2,2),

        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(3, activation='softmax')  # 3 classes
    ])

    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

model = create_custom_cnn()

epochs = 10  # you can increase this if needed

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=epochs
)

# Get true labels and predicted labels
val_ds.reset()  # reset generator before predicting

# Get predictions (probabilities)
pred_probs = model.predict(val_ds)

# Predicted class indices
y_pred = np.argmax(pred_probs, axis=1)

# True class indices
y_true = val_ds.classes

# Print accuracy
acc = accuracy_score(y_true, y_pred)
print(f"Accuracy: {acc*100:.2f}%\n")

# Print detailed classification report
class_names = list(val_ds.class_indices.keys())
print("Classification Report:\n")
print(classification_report(y_true, y_pred, target_names=class_names))

cm = confusion_matrix(y_true, y_pred)

plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest'
)

train_ds = datagen.flow_from_directory(
    leaf_data_path,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='training',
    shuffle=True,
    seed=42
)

val_ds = datagen.flow_from_directory(
    leaf_data_path,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    subset='validation',
    shuffle=False,
    seed=42
)

from tensorflow.keras import layers, models

model = models.Sequential([
    layers.Input(shape=(224, 224, 3)),

    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),
    layers.Dropout(0.25),   # Add dropout

    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),
    layers.Dropout(0.25),   # Add dropout

    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),    # Add dropout

    layers.Dense(3, activation='softmax')
])

from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import EarlyStopping

# Define the model architecture with dropout
model = models.Sequential([
    layers.Input(shape=(224, 224, 3)),

    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),
    layers.Dropout(0.25),

    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),
    layers.Dropout(0.25),

    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),

    layers.Dense(3, activation='softmax')  # 3 classes
])

# Compile the model
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Define EarlyStopping callback
early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

# Train the model
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=20,
    callbacks=[early_stop]
)

val_loss, val_accuracy = model.evaluate(val_ds)
print(f"\nValidation Accuracy: {val_accuracy * 100:.2f}%")

import matplotlib.pyplot as plt

# Plot accuracy
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training vs Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Plot loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training vs Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

import numpy as np
from sklearn.metrics import classification_report, confusion_matrix

# Get class names
class_names = list(train_ds.class_indices.keys())  # or val_ds.class_indices.keys()

# Reset the generator before prediction
val_ds.reset()

# Predict the probabilities
y_pred_probs = model.predict(val_ds, verbose=1)

# Get predicted class indices
y_pred = np.argmax(y_pred_probs, axis=1)

# Get true class indices
y_true = val_ds.classes  # This directly gives you true labels

# Classification Report
print("\nClassification Report:\n")
print(classification_report(y_true, y_pred, target_names=class_names))

# Confusion Matrix
print("\nConfusion Matrix:\n")
print(confusion_matrix(y_true, y_pred))

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Compute confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Plot
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - Custom CNN')
plt.show()