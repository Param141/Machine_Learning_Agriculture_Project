# -*- coding: utf-8 -*-
"""Copy of MobileNetV2_Softmax.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bRtDBuO504NWAo15K_0bsuPGN4cWK-A7
"""

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.preprocessing import image_dataset_from_directory
import matplotlib.pyplot as plt
import os

from google.colab import drive
drive.mount('/content/drive')

# Define dataset path
dataset_path = "/content/drive/MyDrive/leaf_data_final/split_dataset"

import os

# List folders to find the correct path
base_path = "/content/drive/MyDrive"
for root, dirs, files in os.walk(base_path):
    print(root)
    if "split_dataset" in dirs:
        print("âœ… Found split_dataset at:", os.path.join(root, "split_dataset"))
        break

import os

# List top-level folders inside MyDrive
base_path = "/content/drive/MyDrive"
folders = os.listdir(base_path)

print("Folders inside MyDrive:")
for folder in folders:
    print("-", folder)

import zipfile
import os

zip_path = "/content/drive/MyDrive/leaf_data_training.zip"
extract_path = "/content/leaf_data_training"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("âœ… Dataset unzipped to:", extract_path)

print("Contents:")
print(os.listdir("/content/leaf_data_training"))

from tensorflow.keras.utils import image_dataset_from_directory

# Correct dataset path pointing to the 3 class folders
dataset_path = "/content/leaf_data_training/leaf_data_training"

# Image size and batch size
img_size = (224, 224)
batch_size = 32

# Load training dataset (80% of data)
train_ds = image_dataset_from_directory(
    dataset_path,
    validation_split=0.2,
    subset="training",
    seed=123,
    image_size=img_size,
    batch_size=batch_size
)

# Load validation dataset (20% of data)
val_ds = image_dataset_from_directory(
    dataset_path,
    validation_split=0.2,
    subset="validation",
    seed=123,
    image_size=img_size,
    batch_size=batch_size
)

# Print class names to confirm
class_names = train_ds.class_names
print("Class names:", class_names)

from tensorflow.keras import layers, models
from tensorflow.keras.applications import MobileNetV2

# Load MobileNetV2 base model with pretrained ImageNet weights, without the top layer
base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')

# Freeze the base model initially
base_model.trainable = False

# Build the full model by adding classification head on top
model = models.Sequential([
    layers.Rescaling(1./255, input_shape=(224, 224, 3)),
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(3, activation='softmax')  # 3 classes
])

# Compile the model
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

# Train for initial epochs with base model frozen
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=5  # You can increase later
)

# Unfreeze the base model for fine-tuning
base_model.trainable = True

# Freeze the first layers, fine-tune from layer 100 onwards
fine_tune_start = 100
for layer in base_model.layers[:fine_tune_start]:
    layer.trainable = False

# Compile the model with a low learning rate
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Fine-tune for more epochs
fine_tune_epochs = 10
total_epochs = 5 + fine_tune_epochs

history_fine = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=total_epochs,
    initial_epoch=history.epoch[-1]
)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
import tensorflow as tf
import os

# 1. Save your model
model.save("best_mobilenetv2_model.h5")  # Or use .keras if preferred
print("âœ… Model saved as 'best_mobilenetv2_model.h5'")

# 2. Get class names from the dataset
class_names = val_ds.class_names
print("Class names:", class_names)

# 3. Predict labels on validation set
y_true = []
y_pred = []

for images, labels in val_ds:
    preds = model.predict(images)
    y_true.extend(labels.numpy())
    y_pred.extend(np.argmax(preds, axis=1))

# 4. Classification report
print("\nðŸ“Š Classification Report:\n")
print(classification_report(y_true, y_pred, target_names=class_names))

# 5. Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)

plt.figure(figsize=(6, 6))
disp.plot(cmap=plt.cm.Blues, values_format='d')
plt.title("Confusion Matrix")
plt.show()